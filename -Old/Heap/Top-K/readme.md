这一类问题在海量数据类面试题中出现频率最高。问题的形式通常如下：

找到一个大文件或者数据流中出现频率最高的 K 项

这个问题的难点在于，如果条件不一样，解决的办法是完全不一样的，比如：
是否需要精确的 Top K 结果？即，是否允许小概率出错。
数据是离线的还是在线的？即是一个大文件的形式计算一次得到一个结果，还是数据流的形式实时返回结果。

接下来我们来看一个比较简单的算法题，一来让你切身地感受条件不同、解法不同的现象，更重要地是为之后解决最高频 K 项问题做一个铺垫。

在一个整数数组中，找最大的 K 个整数
这个问题可以分为离线和在线两种，两种类型的解法完全不同。

下面我们先来看一下离线问题的解法：
这个问题，我们也可以直接使用 Quick Select 算法（参考资料），在 O(N) 的时间内找到数组的第 K 大的数。然后对前 k 大的数进行排序，时间复杂度是 O(n + k log k)。两种算法都是基于快速排序算法的，十分值得学习。

https://blog.csdn.net/hustyangju/article/details/25399937

在学习完离线问题的解法之后，我们再来看一下在线的问题如何解决，注意两种问题的区别哦。

这里我们再来回顾一下这道题的核心：使用堆来保存当前时刻 top k 的元素。我们的处理主要基于以下几点：

对于每一个中间时刻，前面的处理中，已经不属于 top k 的数据，在后续的处理中，也不可能进入 top k 的行列，因此没有保存的必要。
在已经求出前面所有数据 top k 项的前提下，加入一个新的数据，只需要将新数据与原来 top k 的数据中最小的元素比较就可以了，如果新来的元素更大，则原来 top k 的数据中最小的元素被剔除，将新来的元素加入 top k 的行列；否则保持原来 top k 的数据不变。
根据前面的分析，保存固定数量的 k 个数据，每次选出最小的元素，并支持添加和删除最小的元素的操作，数据结构选取最小堆最合适。

有了最大 K 项 问题的铺垫之后，接下来我们求解最高频 K 项 的问题，就有了直观的解法：

这个算法我们暂且称之为 标准离线算法。主要的使用了两个数据结构：哈希表和最小堆。
我们来分析一下这个算法的时空复杂度：第一步统计所有单词的出现次数，需要 O(N) 的空间和 O(N) 的时间。第二步需要 O(K) 的空间和 O(NlogK) 的时间。总的时间耗费是 O(N log K)，空间耗费是 O(N)。

上面我们给出了求 top K 数据的标准离线算法，假如现在摆在你面前的是上 T（TrillionByte）的数据，就算是全部扫描一遍也是非常漫长的。所以虽然时间复杂度 O (N log k)已经是理论下限了。但是是不是仍然可以加速呢？要解决这一问题，就要用到我们之前所讲过的 map reduce 了。

上一章的课程中，我们已经很详细地介绍了 map reduce 的原理以及优势，接下来我们就来看一下，如何在 top k 的问题中，使用 map reduce 系统呢。

Map Reducer 使用步骤：

通过 Map 步骤，将每一个文件中的单词一个个取出，每个单词构造一个 <Word, 1> 的 Key-value 二元组，作为 Map 的输出。
通过 Reduce 的步骤，每个 Reducer（Reducer 是处理 reduce 的机器） 会处理若干个不同的 Key，在每个 Reducer 一开始初始化的时候，构建一个最小堆（如最开始我们提到的算法），Reducer 在每次 Reduce 操作的时候，输入是 key（某个 word） 和他对应的 values，其实这里我们可以假设 values 就是一堆 1（事实上 Map Reduce 会帮你做一些优化，导致有可能 value 已经被加过，所以实际处理的时候，还是老老实实的把 values 加起来，而不是看一下 values 有多少个）。那么我们把所有的 values 加起来就是当前这个 key（某个 word）的出现次数。那么当我们拿到这个单词的出现次数之后，就可以在当前的 Reducer 里去和最小堆里的第 K 大比大小，来决定是否淘汰当前的第 K 大了。Reducer 在处理完他需要处理的数据之后，就输出他得到的 Top K。
由于可能有多个 Reducers（跟你同时运行的机器数有关，当然一台机器也可能会运行多个 Reducer），因此我们会得到多个 Top K，最后还需要从这些输出中过一遍，得到最终的 Top K。这个步骤已经在 Map Reduce 之外了，用一个单独的代码扫一遍就可以了。

在标准离线算法中，我们花费了 O(N)的空间消耗，以前就是把所有的单词放入到了内存中。但在现实场景中，这个做法很可能是不行的，因为 N 可能非常的大。即使我们使用 Map reduce 系统，使用多台机器，分配到每台机器的时候，仍然可能出现无法全部加载到内存的情况。

在讨论空间优化方法时，我们简化一下原来的问题，只关注存储空间：
简化问题：假设现在只有一台机器，内存为 1G，你有一个 1T 大小的文件，需要统计里面最高频的 K 个单词。在这个问题中，我们主要用到哈希算法来优化我们的空间效率。先来介绍一些什么是 Hash 和 Hash Code。

Hash（哈希），是一个非常常见的算法（HashTable 哈希表才是数据结构，Hash 是算法）。我们在《九章算法班》中对哈希算法做过详细的介绍，如果你不知道哈希算法做了什么事情，你可以假设已经存在这样一个哈希函数，这个哈希函数对于同一个 Key，会返回一个固定的，无规律的 整数值。在工程中，你通常不需要不需要自己实现哈希函数，有很多库可以直接用。你可以在网上搜索相关的你所使用语言的库的哈希函数资料。

所谓的固定的，值得是，同样的 Key，得到的结果，肯定是同样的。同一个单词不可能一会儿算出来的哈希值（Hash Code）是 1，一会儿是 2。
所谓的无规律，说的是，如果你给哈希函数一大堆不同的 Key 的时候，他产生的哈希值不会扎堆，分布还是比较均匀的。
另外还有一个特点是，哈希值是可能重复的，并不是一对一的。也就是两个不同的 Key，可能得到同一个哈希值。这个特性并不影响我们的计算。

===
在了解了哈希算法之后，我们要如何使用哈希算法来解决内存问题呢？主要分为以下三步：

===
我们只需要先将文件扫描一次，把每个单词作为 Key，算一下他的哈希值，然后模上大概 2000 - 10000 的这样一个数。之所以取这这么一个数是因为，内存的大小是 1G，那么如果将 1T 的文件分成若干个 1G 大小的小文件的话，那么理想需要 1000 个文件。因此反之，如果你将所有的单词，分成了 1000 组的话，理想状况下，每组大概就是 1G 个不同的单词。当然这是理想状况，所以实际上处理的时候，你可以分成 2000 组比较保险。10000 组当然更保险了，但是可能就没有合理利用上内存了。实际做的时候，你可以看一下分成 2000 行不行，不行的话，再放大分组数。

对于每个文件，分别导入内存进行处理，即使用我们最开始提到的标准离线算法 - 哈希表+最小堆。每一组文件得到一个 Top K。

类似于 Map Reduce 一样，我们得到了若干个 Top K，我们最后把这若干个 Top K 再合并一次就好了。

===
前面我们讨论了最高频 k 项的离线算法，接下来我们来讨论一下最高频 k 项的在线算法。

我们还是通过一个实际问题来学习：
数据流中不断流过一些单词，提供一个接口，返回当前出现过的单词中，频次最高的 Top K 个单词。数值 K 在最开始便已经给出。
即：对于给定的 K，是想两个接口：
add(word)

# 添加一个单词到集合中

topk()

# 返回集合中的 Top K 的高频词

===
一般来说，数据流（Data Stream）问题就是我们所说的在线问题。数据流问题的特点是：你没有第二次从头访问数据的机会。
因此在离线算法中，先通过哈希表（HashMap）计数，再通过堆（Heap）来统计 Top K 的方法就行不通了。
类似于标准离线算法，这里我们给出标准在线算法，思路是：一边计数的同时，一边比较 Top K

===
我们来讨论一下标准在线算法的时空复杂度：

add 的时间复杂度是 O(logK) 的，因为最坏情况下，就是 pop 掉一个单词，push 进去一个新的单词。由于 hashheap 的大小最多是 K，那么复杂度为 O(logK)
topk 的时间复杂度是 O(KlogK)。
这个算法的空间复杂度，为计数所用的哈希表的空间复杂度。为数据流中到当前时刻为止的单词总个数。

前面我们讨论了标准在线算法。空间复杂度与数据流中流过的数据大小总和有关，也就是用于计数的那个哈希表的耗费。如果你需要设计一个统计 Google 热门搜索的系统，那么这个数据量是很恐怖的。根据 Google 官方公布的数据，一天有 35 亿次搜索，假设每条搜索记录 20 个字节，那么会耗费 70G 的空间至少。通常哈希表的耗费要比实际存储的数据大小要大几倍才能保证效率，那么可想而知这个内存耗费是多么的恐怖。

===
根据这么多年的发展经验，想要寻找一个在线的，精确的，省空间的 Top K 高频项算法是不可能的。正如我们在数据库中，无法同时满足 “实时性”，“可用性”和“一致性”一样。

===
因此我们必须损失掉一个因子，这个因子就是准确性，换而言之就是用损失精度换空间的方法。
精确性是说，比如我求得了 Top 10 的查询，那么这 10 个查询中，可能会存在一个查询，他的实际排名在 Top 10 之后。又或者 Top 10 的相对排名并不正确，原本第一名的跑去了第二名。幸运的是，在实际的系统应用中，人们对精确性的要求是不高的。比如你会去验证微博热门搜索中的那些搜索真的是 Top 10 的热门搜索么？你也无从验证。用户是无法感知这个不精确性的。这就留给了我们优化空间的余地。

===
已经有很多的科研学者们研究过精度换空间的方法，并发明了一些较为成熟的算法：

Lossy Counting
Sticky Sample
Space Saving
Efficient Count
Hash Count
...

===
接下来我们来介绍一个比较容易掌握的，在标准在线的算法的基础上改进最小的：Hash Count。

===
上面这个算法中，和标准在线算法相比，唯一的区别在于，我们将原本记录所有单词的出现次数的哈希表，换成了一个根据内存大小能开多大开多大的数组。这个数组的每个下标存储了“某些”单词的出现次数。我们使用了哈希函数（hashfunc），对每个单词计算他的哈希值（hashcode），将这个值模整个 hashcount 数组的大小得到一个下标（index），然后用这个下标对应的计数来代表这个单词的出现次数。有了这个单词的出现次数之后，再拿去 hash heap 里进行比较就可以了。

===
你应该马上会发现问题，如果有两个单词，他们的 hashcode % hashcount.size 的结果相同，那么他们的计数会被叠加到一起。从而导致计算结果的不精确。比如下面这种情况，求 Top 3 的单词，目前的统计结果是 {word1: 100, word2: 99, word: 98}。这个时候来了一个新的单词 word4，word4 从没出现过，计数本应该是 0，但是很巧的是，他的 hashcode % hashcount.size 的结果和 word1 是一样的。那么他就会把 word1 的计数当作是自己的计数，从而得到 100 + 1 = 101，成为 Top 1 的单词，并且挤掉了本应在 Top 3 的 word3。

===
上述问题对精度的影响到底有多大呢？事实上，根据“长尾效应”（Google 一下），在实际数据的统计中，由于 Top K 的 K 相对于整个数据流集合中的不同数据项个数 N 的关系是 K 远远小于 N，而 Top K 的这些数据项的计数又远远大于其他的数据项。因此，Top K 的 hashcode % hashcount.size 扎堆的可能性是非常非常小的。因此这个算法的精确度也就并不会太差。

===
在详细地学习了最高频 K 项问题的解答方法之后，让我们用几个面试真题来实战演练一下吧。

===
No.1 离地球最近的 K 颗星星
给你 N 个星星的位置坐标，找到离地球最近的 M 颗星星。

===
No.2 最近 7 天的热门歌曲

问题描述：
计一个听歌统计系统，返回用户 7 天内听的最多 10 首的歌

===
问题分析：
在解决这个问题之前，我们需要和面试官沟通如下的几个问题条件：

7 天和 10 首歌这个数字是固定的么？有可能一会儿 7 天一会儿 10 天，一会儿 10 首歌一会儿 8 首歌么？
对实时性要求严格么？即，是否允许一定时间的延迟？比如一首个一分钟内被点爆，是否需要在这 1 分钟之内在榜单中体现出来？
澄清问题是面试中重要的一个步骤，因为上述问题的答案，稍有不同，则算法的设计，系统的设计就截然不同。
我们先做如下的合理假设：

7 天 10 首歌这两个数字是固定的。
对实时性要求不严格，可以有 1 小时的误差。
